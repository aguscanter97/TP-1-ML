{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a70a96f",
   "metadata": {},
   "source": [
    "## Functions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25c2a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor, GradientBoostingRegressor,\n",
    "    BaggingRegressor, RandomForestRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76d8a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar nombres de columnas\n",
    "def clean_column_names(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [\n",
    "        re.sub(r'[^A-Za-z0-9_]+', '_', col)  # deja solo letras, números y \"_\"\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2801132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_log_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Funciones auxiliares\n",
    "def mape_percent(y_true, y_pred):\n",
    "    # MAPE en porcentaje\n",
    "    return 100 * mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    # MSLE requiere no-negativos\n",
    "    y_true_safe = np.maximum(y_true, 0)\n",
    "    y_pred_safe = np.maximum(y_pred, 0)\n",
    "    return np.sqrt(mean_squared_log_error(y_true_safe, y_pred_safe))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Evaluación de modelos\n",
    "def fit_transform_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    models = [\n",
    "        LinearRegression(n_jobs=-1),\n",
    "        KNeighborsRegressor(n_neighbors=5, n_jobs=-1),\n",
    "        AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "        DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "        GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "        BaggingRegressor(n_estimators=50, n_jobs=-1, random_state=42),\n",
    "        RandomForestRegressor(n_estimators=100, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        LGBMRegressor(n_estimators=200, learning_rate=0.1, max_depth=-1, n_jobs=-1, random_state=42, verbose=-1),\n",
    "        xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6,\n",
    "                         subsample=0.8, colsample_bytree=0.8, n_jobs=-1,\n",
    "                         tree_method=\"hist\", random_state=42, verbosity=0),\n",
    "        CatBoostRegressor(iterations=200, depth=6, learning_rate=0.1, verbose=False, random_state=42)\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        mape_val  = mape_percent(y_test, predictions)\n",
    "        rmsle_val = rmsle(y_test, predictions)\n",
    "        rmse_val  = root_mean_squared_error(y_test, predictions)\n",
    "\n",
    "        print(f\"{model_name} MAPE: {mape_val:.2f}% | RMSLE: {rmsle_val:.4f} | RMSE: {rmse_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567f53f",
   "metadata": {},
   "source": [
    "## Model test with application_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec8f20",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50866c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train_2_Prework.parquet\", engine='fastparquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87565d80",
   "metadata": {},
   "source": [
    "### Quick prework with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "73b77883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La librería fastai tiene varias funcionalidad para preprocesar datasets. \n",
    "# En particular para poder usar un Random Forests de ScikitLearn necesitamos que todas las variables sean numéricas y no tener valores faltantas.\n",
    "# En particular vamos a usar dos preprocesamientos: Categorify y FillMissing. Por ahora solo definimos los preprocesamientos y luego se aplican.\n",
    "procs = [Categorify, FillMissing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "320fe53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Además del preprocesamiento, vamos a dividir nuestro dataset en train y validation. \n",
    "# En este caso no sería una buena elección hacer una partición aleatoria porque estamos trabajando con datos temporales. \n",
    "# Vamos a poner una fecha de corte para dividir el dataset.\n",
    "# - dep_var='TARGET': excluye esta columna del análisis porque es la variable que se quiere predecir.\n",
    "# - max_card=10: si una columna tiene menos de 10 valores únicos, se considera categórica.\n",
    "# - preproc_names=procs: aplica transformaciones como Categorify, FillMissing, que están definidas en procs\n",
    "\n",
    "cont,cat = cont_cat_split(train_df, 1, dep_var='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10d07314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índices del DataFrame completo\n",
    "idxs = list(range(len(train_df)))\n",
    "\n",
    "# Partición aleatoria 80/20\n",
    "train_idx, valid_idx = train_test_split(idxs, test_size=0.3, random_state=42)\n",
    "\n",
    "# Adaptación para TabularPandas\n",
    "splits = (list(train_idx), list(valid_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb2031a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['ad_type', 'currency', 'l5', 'l6', 'operation_type', 'price_period']\n"
     ]
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ===== 1) Preparar df y target =====\n",
    "df = train_df.copy()\n",
    "\n",
    "# target precio/m2 con guardas\n",
    "df[\"price_m2\"] = df[\"price\"] / df[\"surface_total\"].replace(0, np.nan)\n",
    "df[\"lat\"] = pd.to_numeric(df[\"lat\"], errors=\"coerce\")\n",
    "df[\"lon\"] = pd.to_numeric(df[\"lon\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"price_m2\"]).copy()   # sin target NaN\n",
    "\n",
    "# ===== 2) Definir columnas =====\n",
    "cat = df.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "cont = [c for c in df.select_dtypes(include=[\"number\"]).columns if c != \"price_m2\"]\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = df.dropna(subset=[\"price_m2\"]).copy()\n",
    "all_nan_cols   = df.columns[df.isna().all()].tolist()                         # 100% NaN (ej. l6)\n",
    "constant_cols  = [c for c in df.columns if df[c].nunique(dropna=True) <= 1]   # sin variabilidad\n",
    "hi_null_cols   = df.columns[df.isna().mean() > 0.95].tolist()                 # >95% NaN\n",
    "to_drop = sorted(set(all_nan_cols) | set(constant_cols) | set(hi_null_cols))\n",
    "\n",
    "print(\"Dropping columns:\", to_drop)  # debería incluir 'l6'\n",
    "df = df.drop(columns=to_drop)\n",
    "\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cont = [c for c in num_cols if c != \"price_m2\"]\n",
    "cat  = [c for c in df.columns if c not in cont + [\"price_m2\"]]\n",
    "\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "splits = RandomSplitter(valid_pct=0.2, seed=42)(range_of(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1847efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\60083400\\AppData\\Local\\anaconda3\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "to = TabularPandas(df, procs, cat, cont, y_names='price', splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f6e6c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: []\n",
      "NaN en X_train: 0\n",
      "NaN en X_valid: 0\n"
     ]
    }
   ],
   "source": [
    "# === BLOQUE SEGURO: usar salidas de TabularPandas para evitar NaN ===\n",
    "# Requiere que exista el objeto `to = TabularPandas(...)` con procs [Categorify, FillMissing, Normalize]\n",
    "try:\n",
    "    X_train, y_train = to.train.xs.copy(), to.train.y.values.ravel()\n",
    "    X_valid, y_valid = to.valid.xs.copy(), to.valid.y.values.ravel()\n",
    "except NameError as e:\n",
    "    raise RuntimeError(\"No existe el objeto 'to'. Asegúrate de haber creado TabularPandas antes.\") from e\n",
    "\n",
    "all_nan_cols   = df.columns[df.isna().all()].tolist()                         # 100% NaN (ej. l6)\n",
    "constant_cols  = [c for c in df.columns if df[c].nunique(dropna=True) <= 1]   # sin variabilidad\n",
    "hi_null_cols   = df.columns[df.isna().mean() > 0.95].tolist()                 # >95% NaN\n",
    "to_drop = sorted(set(all_nan_cols) | set(constant_cols) | set(hi_null_cols))\n",
    "\n",
    "print(\"Dropping columns:\", to_drop)  # debería incluir 'l6'\n",
    "\n",
    "# Chequeos duros de NaN (deben dar 0)\n",
    "print(\"NaN en X_train:\", int(X_train.isna().sum().sum()))\n",
    "print(\"NaN en X_valid:\", int(X_valid.isna().sum().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3e31da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224100, 56025)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to.train),len(to.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ba2acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>created_on</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>surface_total</th>\n",
       "      <th>surface_covered</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "      <th>covered_ratio</th>\n",
       "      <th>year_created</th>\n",
       "      <th>month_created</th>\n",
       "      <th>age_of_ad</th>\n",
       "      <th>price_m2</th>\n",
       "      <th>lat_na</th>\n",
       "      <th>lon_na</th>\n",
       "      <th>rooms_na</th>\n",
       "      <th>bedrooms_na</th>\n",
       "      <th>bathrooms_na</th>\n",
       "      <th>surface_covered_na</th>\n",
       "      <th>covered_ratio_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>976371</th>\n",
       "      <td>1.944583</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>0.308681</td>\n",
       "      <td>-0.063553</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027854</td>\n",
       "      <td>-0.159933</td>\n",
       "      <td>-0.589070</td>\n",
       "      <td>-0.108352</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>77799</td>\n",
       "      <td>207108</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.299272</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>-0.90205</td>\n",
       "      <td>0.326434</td>\n",
       "      <td>1.269102</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143386</th>\n",
       "      <td>-1.036305</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>0.664449</td>\n",
       "      <td>-1.197887</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027854</td>\n",
       "      <td>-0.159933</td>\n",
       "      <td>0.367002</td>\n",
       "      <td>-0.095983</td>\n",
       "      <td>-0.030901</td>\n",
       "      <td>96032</td>\n",
       "      <td>156078</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.299272</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>-0.90205</td>\n",
       "      <td>0.637303</td>\n",
       "      <td>1.000483</td>\n",
       "      <td>1072.727295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415316</th>\n",
       "      <td>-0.060889</td>\n",
       "      <td>138</td>\n",
       "      <td>203</td>\n",
       "      <td>138</td>\n",
       "      <td>0.293270</td>\n",
       "      <td>-0.054636</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027854</td>\n",
       "      <td>-1.160798</td>\n",
       "      <td>-0.589070</td>\n",
       "      <td>-0.105927</td>\n",
       "      <td>-0.060324</td>\n",
       "      <td>85026</td>\n",
       "      <td>23423</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.127918</td>\n",
       "      <td>-0.004603</td>\n",
       "      <td>-0.90205</td>\n",
       "      <td>1.259042</td>\n",
       "      <td>0.237951</td>\n",
       "      <td>2971.014404</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  start_date  end_date  created_on       lat       lon  l1  l2   l3  l4     rooms  bedrooms  bathrooms  surface_total  surface_covered  title  description  property_type     price  covered_ratio  year_created  month_created  age_of_ad     price_m2  lat_na  lon_na  rooms_na  bedrooms_na  bathrooms_na  surface_covered_na  covered_ratio_na\n",
       "976371  1.944583          27        41          27  0.308681 -0.063553   1   7  660   0 -0.027854 -0.159933  -0.589070      -0.108352        -0.063522  77799       207108              8 -0.299272       0.002644      -0.90205       0.326434   1.269102  2000.000000       1       1         2            2             1                   1                 1\n",
       "143386 -1.036305          56        72          56  0.664449 -1.197887   1   4  390   0 -0.027854 -0.159933   0.367002      -0.095983        -0.030901  96032       156078              8 -0.299272       0.002644      -0.90205       0.637303   1.000483  1072.727295       1       1         2            2             1                   1                 1\n",
       "415316 -0.060889         138       203         138  0.293270 -0.054636   1   7  443   0 -0.027854 -1.160798  -0.589070      -0.105927        -0.060324  85026        23423              4 -0.127918      -0.004603      -0.90205       1.259042   0.237951  2971.014404       1       1         2            1             1                   1                 1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una vez hecho el preprocesamiento, se puede ver que los valores del dataframe son todos numéricos.\n",
    "to.items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da982e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>created_on</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>surface_total</th>\n",
       "      <th>surface_covered</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>property_type</th>\n",
       "      <th>price</th>\n",
       "      <th>covered_ratio</th>\n",
       "      <th>year_created</th>\n",
       "      <th>month_created</th>\n",
       "      <th>age_of_ad</th>\n",
       "      <th>price_m2</th>\n",
       "      <th>lat_na</th>\n",
       "      <th>lon_na</th>\n",
       "      <th>rooms_na</th>\n",
       "      <th>bedrooms_na</th>\n",
       "      <th>bathrooms_na</th>\n",
       "      <th>surface_covered_na</th>\n",
       "      <th>covered_ratio_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>2.801250e+05</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "      <td>280125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000031</td>\n",
       "      <td>158.530181</td>\n",
       "      <td>272.967104</td>\n",
       "      <td>158.530181</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>1.069476</td>\n",
       "      <td>9.555084</td>\n",
       "      <td>397.602399</td>\n",
       "      <td>140.257721</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>82714.240935</td>\n",
       "      <td>109406.606968</td>\n",
       "      <td>4.199404</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>1.906913e+03</td>\n",
       "      <td>1.127240</td>\n",
       "      <td>1.127240</td>\n",
       "      <td>1.308237</td>\n",
       "      <td>1.455750</td>\n",
       "      <td>1.185296</td>\n",
       "      <td>1.161499</td>\n",
       "      <td>1.161499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000305</td>\n",
       "      <td>101.263015</td>\n",
       "      <td>145.345692</td>\n",
       "      <td>101.263015</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.995251</td>\n",
       "      <td>0.447577</td>\n",
       "      <td>11.394756</td>\n",
       "      <td>219.302012</td>\n",
       "      <td>238.187339</td>\n",
       "      <td>1.000338</td>\n",
       "      <td>1.979530</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>1.012130</td>\n",
       "      <td>1.107909</td>\n",
       "      <td>47253.169024</td>\n",
       "      <td>61769.154997</td>\n",
       "      <td>2.472680</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.941927</td>\n",
       "      <td>1.000032</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>1.000511</td>\n",
       "      <td>4.851974e+03</td>\n",
       "      <td>0.333242</td>\n",
       "      <td>0.333242</td>\n",
       "      <td>0.461766</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.388538</td>\n",
       "      <td>0.367992</td>\n",
       "      <td>0.367992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.530717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-22.314139</td>\n",
       "      <td>-6.851133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.438810</td>\n",
       "      <td>-4.163394</td>\n",
       "      <td>-0.589070</td>\n",
       "      <td>-0.171170</td>\n",
       "      <td>-0.209997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521836</td>\n",
       "      <td>-0.097369</td>\n",
       "      <td>-0.902050</td>\n",
       "      <td>-1.849652</td>\n",
       "      <td>-1.859010</td>\n",
       "      <td>-5.750000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.893183</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.190198</td>\n",
       "      <td>-0.069610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.733332</td>\n",
       "      <td>-0.159933</td>\n",
       "      <td>-0.589070</td>\n",
       "      <td>-0.109565</td>\n",
       "      <td>-0.069278</td>\n",
       "      <td>47818.000000</td>\n",
       "      <td>56414.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.358360</td>\n",
       "      <td>-0.014804</td>\n",
       "      <td>-0.902050</td>\n",
       "      <td>-0.606175</td>\n",
       "      <td>-0.853855</td>\n",
       "      <td>8.750000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.050208</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.273895</td>\n",
       "      <td>-0.059901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.027854</td>\n",
       "      <td>-0.159933</td>\n",
       "      <td>-0.589070</td>\n",
       "      <td>-0.097195</td>\n",
       "      <td>-0.052648</td>\n",
       "      <td>74391.000000</td>\n",
       "      <td>114187.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.230927</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>-0.902050</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.159965</td>\n",
       "      <td>1.739475e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.747618</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.295299</td>\n",
       "      <td>-0.024340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>-0.027854</td>\n",
       "      <td>-0.159933</td>\n",
       "      <td>0.367002</td>\n",
       "      <td>-0.052083</td>\n",
       "      <td>-0.018108</td>\n",
       "      <td>123086.000000</td>\n",
       "      <td>161551.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.029649</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>1.108586</td>\n",
       "      <td>0.948173</td>\n",
       "      <td>0.896501</td>\n",
       "      <td>2.549020e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.002324</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>10.231139</td>\n",
       "      <td>27.502083</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>752.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>26.074825</td>\n",
       "      <td>898.616975</td>\n",
       "      <td>17.576286</td>\n",
       "      <td>48.385573</td>\n",
       "      <td>247.435092</td>\n",
       "      <td>172602.000000</td>\n",
       "      <td>213956.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>90.069385</td>\n",
       "      <td>339.949033</td>\n",
       "      <td>1.108586</td>\n",
       "      <td>1.569911</td>\n",
       "      <td>1.511726</td>\n",
       "      <td>1.817667e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     start_date       end_date     created_on            lat            lon             l1             l2             l3             l4          rooms       bedrooms      bathrooms  surface_total  surface_covered          title    description  property_type          price  covered_ratio   year_created  month_created      age_of_ad      price_m2         lat_na         lon_na       rooms_na    bedrooms_na   bathrooms_na  surface_covered_na  covered_ratio_na\n",
       "count  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000    280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000  2.801250e+05  280125.000000  280125.000000  280125.000000  280125.000000  280125.000000       280125.000000     280125.000000\n",
       "mean       -0.000031     158.530181     272.967104     158.530181      -0.000655      -0.000195       1.069476       9.555084     397.602399     140.257721      -0.001546       0.002985      -0.000884       0.000821         0.001345   82714.240935  109406.606968       4.199404      -0.000068      -0.000439       0.000294       0.000679      -0.000910  1.906913e+03       1.127240       1.127240       1.308237       1.455750       1.185296            1.161499          1.161499\n",
       "std         1.000305     101.263015     145.345692     101.263015       0.999965       0.995251       0.447577      11.394756     219.302012     238.187339       1.000338       1.979530       0.999948       1.012130         1.107909   47253.169024   61769.154997       2.472680       0.998055       0.941927       1.000032       0.999563       1.000511  4.851974e+03       0.333242       0.333242       0.461766       0.498039       0.388538            0.367992          0.367992\n",
       "min        -1.530717       1.000000       0.000000       1.000000     -22.314139      -6.851133       1.000000       1.000000       0.000000       0.000000      -1.438810      -4.163394      -0.589070      -0.171170        -0.209997       1.000000       0.000000       1.000000      -0.521836      -0.097369      -0.902050      -1.849652      -1.859010 -5.750000e+04       1.000000       1.000000       1.000000       1.000000       1.000000            1.000000          1.000000\n",
       "25%        -0.893183      68.000000     151.000000      68.000000       0.190198      -0.069610       1.000000       2.000000     214.000000       0.000000      -0.733332      -0.159933      -0.589070      -0.109565        -0.069278   47818.000000   56414.000000       3.000000      -0.358360      -0.014804      -0.902050      -0.606175      -0.853855  8.750000e+02       1.000000       1.000000       1.000000       1.000000       1.000000            1.000000          1.000000\n",
       "50%        -0.050208     145.000000     287.000000     145.000000       0.273895      -0.059901       1.000000       7.000000     443.000000       0.000000      -0.027854      -0.159933      -0.589070      -0.097195        -0.052648   74391.000000  114187.000000       4.000000      -0.230927      -0.005929      -0.902050       0.015564       0.159965  1.739475e+03       1.000000       1.000000       1.000000       1.000000       1.000000            1.000000          1.000000\n",
       "75%         0.747618     241.000000     424.000000     241.000000       0.295299      -0.024340       1.000000       7.000000     572.000000     233.000000      -0.027854      -0.159933       0.367002      -0.052083        -0.018108  123086.000000  161551.000000       5.000000       0.029649       0.002644       1.108586       0.948173       0.896501  2.549020e+03       1.000000       1.000000       2.000000       2.000000       1.000000            1.000000          1.000000\n",
       "max         2.002324     346.000000     448.000000     346.000000      10.231139      27.502083       4.000000      42.000000     752.000000     784.000000      26.074825     898.616975      17.576286      48.385573       247.435092  172602.000000  213956.000000      10.000000      90.069385     339.949033       1.108586       1.569911       1.511726  1.817667e+06       2.000000       2.000000       2.000000       2.000000       2.000000            2.000000          2.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.items.describe(include='all')  # Para ver estadísticas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69030966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 224100 entries, 976371 to 450282\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   start_date          224100 non-null  int16  \n",
      " 1   end_date            224100 non-null  int16  \n",
      " 2   created_on          224100 non-null  int16  \n",
      " 3   l1                  224100 non-null  int8   \n",
      " 4   l2                  224100 non-null  int8   \n",
      " 5   l3                  224100 non-null  int16  \n",
      " 6   l4                  224100 non-null  int16  \n",
      " 7   title               224100 non-null  int32  \n",
      " 8   description         224100 non-null  int32  \n",
      " 9   property_type       224100 non-null  int8   \n",
      " 10  lat_na              224100 non-null  int8   \n",
      " 11  lon_na              224100 non-null  int8   \n",
      " 12  rooms_na            224100 non-null  int8   \n",
      " 13  bedrooms_na         224100 non-null  int8   \n",
      " 14  bathrooms_na        224100 non-null  int8   \n",
      " 15  surface_covered_na  224100 non-null  int8   \n",
      " 16  covered_ratio_na    224100 non-null  int8   \n",
      " 17  id                  224100 non-null  float64\n",
      " 18  lat                 224100 non-null  float64\n",
      " 19  lon                 224100 non-null  float64\n",
      " 20  rooms               224100 non-null  float64\n",
      " 21  bedrooms            224100 non-null  float64\n",
      " 22  bathrooms           224100 non-null  float64\n",
      " 23  surface_total       224100 non-null  float64\n",
      " 24  surface_covered     224100 non-null  float64\n",
      " 25  price               224100 non-null  float64\n",
      " 26  covered_ratio       224100 non-null  float64\n",
      " 27  year_created        224100 non-null  float64\n",
      " 28  month_created       224100 non-null  float64\n",
      " 29  age_of_ad           224100 non-null  float64\n",
      "dtypes: float64(13), int16(5), int32(2), int8(10)\n",
      "memory usage: 29.9 MB\n"
     ]
    }
   ],
   "source": [
    "to.train.xs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49f9ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que el preprocesamiento puede tardar, guardamos el objeto en memoria para futuro uso\n",
    "save_pickle('./df_train-tabular-object.pkl',to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23830c24",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3190449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MAPE: 0.00% | RMSLE: 0.0000 | RMSE: 0.0000\n",
      "KNeighborsRegressor MAPE: 2222.29% | RMSLE: 0.3113 | RMSE: 0.8557\n",
      "AdaBoostRegressor MAPE: 867.22% | RMSLE: 0.1041 | RMSE: 0.2350\n",
      "DecisionTreeRegressor MAPE: 1.27% | RMSLE: 0.0017 | RMSE: 0.0426\n",
      "GradientBoostingRegressor MAPE: 109.16% | RMSLE: 0.0039 | RMSE: 0.0289\n",
      "BaggingRegressor MAPE: 0.19% | RMSLE: 0.0017 | RMSE: 0.0452\n",
      "RandomForestRegressor MAPE: 0.66% | RMSLE: 0.0018 | RMSE: 0.0468\n",
      "LGBMRegressor MAPE: 4.19% | RMSLE: 0.0217 | RMSE: 0.1637\n",
      "XGBRegressor MAPE: 127.80% | RMSLE: 0.0370 | RMSE: 0.2641\n",
      "CatBoostRegressor MAPE: 310.35% | RMSLE: 0.0333 | RMSE: 0.4654\n"
     ]
    }
   ],
   "source": [
    "# Cargar el objeto TabularPandas desde el pickle\n",
    "to = load_pickle('./df_train-tabular-object.pkl')\n",
    "\n",
    "# Extraer features y target\n",
    "xs, y = to.train.xs, to.train.y\n",
    "valid_xs, valid_y = to.valid.xs, to.valid.y\n",
    "\n",
    "# Muestreo\n",
    "sample_frac = 0.20   # 100% de las filas\n",
    "sampled_xs = xs.sample(frac=sample_frac, random_state=42)\n",
    "sampled_y = y.loc[sampled_xs.index] \n",
    "\n",
    "# Copias para trabajar con scikit-learn\n",
    "X = sampled_xs.copy()\n",
    "target = sampled_y.copy()\n",
    "\n",
    "# Ejecutar evaluación\n",
    "fit_transform_model(X, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
