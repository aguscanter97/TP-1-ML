{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a70a96f",
   "metadata": {},
   "source": [
    "## Functions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c2a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostRegressor, GradientBoostingRegressor,\n",
    "    BaggingRegressor, RandomForestRegressor\n",
    ")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d8a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar nombres de columnas\n",
    "def clean_column_names(df):\n",
    "    df = df.copy()\n",
    "    df.columns = [\n",
    "        re.sub(r'[^A-Za-z0-9_]+', '_', col)  # deja solo letras, números y \"_\"\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2801132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Evaluación de modelos\n",
    "def fit_transform_model(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = [\n",
    "        LinearRegression(n_jobs=-1),\n",
    "        KNeighborsRegressor(n_neighbors=5, n_jobs=-1),\n",
    "        AdaBoostRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "        DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "        GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),\n",
    "        BaggingRegressor(n_estimators=50, n_jobs=-1, random_state=42),\n",
    "        RandomForestRegressor(n_estimators=100, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        LGBMRegressor(n_estimators=200,learning_rate=0.1,max_depth=-1,n_jobs=-1,random_state=42,verbose=-1),\n",
    "        xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=6,subsample=0.8, colsample_bytree=0.8, n_jobs=-1, tree_method=\"hist\", random_state=42, verbosity=0),\n",
    "        CatBoostRegressor(iterations=200, depth=6, learning_rate=0.1, verbose=False, random_state=42)\n",
    "    ]   \n",
    "\n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        rmse = root_mean_squared_error(y_test, predictions)\n",
    "        print(f\"{model_name} RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567f53f",
   "metadata": {},
   "source": [
    "## Model test with application_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec8f20",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50866c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./home-credit-default-risk/application_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87565d80",
   "metadata": {},
   "source": [
    "### Quick prework with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b77883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La librería fastai tiene varias funcionalidad para preprocesar datasets. \n",
    "# En particular para poder usar un Random Forests de ScikitLearn necesitamos que todas las variables sean numéricas y no tener valores faltantas.\n",
    "# En particular vamos a usar dos preprocesamientos: Categorify y FillMissing. Por ahora solo definimos los preprocesamientos y luego se aplican.\n",
    "procs = [Categorify, FillMissing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320fe53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Además del preprocesamiento, vamos a dividir nuestro dataset en train y validation. \n",
    "# En este caso no sería una buena elección hacer una partición aleatoria porque estamos trabajando con datos temporales. \n",
    "# Vamos a poner una fecha de corte para dividir el dataset.\n",
    "# - dep_var='TARGET': excluye esta columna del análisis porque es la variable que se quiere predecir.\n",
    "# - max_card=10: si una columna tiene menos de 10 valores únicos, se considera categórica.\n",
    "# - preproc_names=procs: aplica transformaciones como Categorify, FillMissing, que están definidas en procs\n",
    "\n",
    "cont,cat = cont_cat_split(train_df, 1, dep_var='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d07314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índices del DataFrame completo\n",
    "idxs = list(range(len(train_df)))\n",
    "\n",
    "# Partición aleatoria 80/20\n",
    "train_idx, valid_idx = train_test_split(idxs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adaptación para TabularPandas\n",
    "splits = (list(train_idx), list(valid_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1847efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n",
      "c:\\Users\\julia\\OneDrive\\Escritorio\\Archivos\\Capacitación\\Maestría\\03. Machine Learning\\.venv\\Lib\\site-packages\\fastai\\tabular\\core.py:316: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  to.loc[:,n+'_na'] = missing[n]\n"
     ]
    }
   ],
   "source": [
    "to = TabularPandas(train_df, procs, cat, cont, y_names='TARGET', splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e31da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246008, 61503)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to.train),len(to.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba2acec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>AMT_ANNUITY_na</th>\n",
       "      <th>AMT_GOODS_PRICE_na</th>\n",
       "      <th>OWN_CAR_AGE_na</th>\n",
       "      <th>CNT_FAM_MEMBERS_na</th>\n",
       "      <th>EXT_SOURCE_1_na</th>\n",
       "      <th>EXT_SOURCE_2_na</th>\n",
       "      <th>EXT_SOURCE_3_na</th>\n",
       "      <th>APARTMENTS_AVG_na</th>\n",
       "      <th>BASEMENTAREA_AVG_na</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG_na</th>\n",
       "      <th>YEARS_BUILD_AVG_na</th>\n",
       "      <th>COMMONAREA_AVG_na</th>\n",
       "      <th>ELEVATORS_AVG_na</th>\n",
       "      <th>ENTRANCES_AVG_na</th>\n",
       "      <th>FLOORSMAX_AVG_na</th>\n",
       "      <th>FLOORSMIN_AVG_na</th>\n",
       "      <th>LANDAREA_AVG_na</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG_na</th>\n",
       "      <th>LIVINGAREA_AVG_na</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG_na</th>\n",
       "      <th>NONLIVINGAREA_AVG_na</th>\n",
       "      <th>APARTMENTS_MODE_na</th>\n",
       "      <th>BASEMENTAREA_MODE_na</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE_na</th>\n",
       "      <th>YEARS_BUILD_MODE_na</th>\n",
       "      <th>COMMONAREA_MODE_na</th>\n",
       "      <th>ELEVATORS_MODE_na</th>\n",
       "      <th>ENTRANCES_MODE_na</th>\n",
       "      <th>FLOORSMAX_MODE_na</th>\n",
       "      <th>FLOORSMIN_MODE_na</th>\n",
       "      <th>LANDAREA_MODE_na</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE_na</th>\n",
       "      <th>LIVINGAREA_MODE_na</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE_na</th>\n",
       "      <th>NONLIVINGAREA_MODE_na</th>\n",
       "      <th>APARTMENTS_MEDI_na</th>\n",
       "      <th>BASEMENTAREA_MEDI_na</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI_na</th>\n",
       "      <th>YEARS_BUILD_MEDI_na</th>\n",
       "      <th>COMMONAREA_MEDI_na</th>\n",
       "      <th>ELEVATORS_MEDI_na</th>\n",
       "      <th>ENTRANCES_MEDI_na</th>\n",
       "      <th>FLOORSMAX_MEDI_na</th>\n",
       "      <th>FLOORSMIN_MEDI_na</th>\n",
       "      <th>LANDAREA_MEDI_na</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI_na</th>\n",
       "      <th>LIVINGAREA_MEDI_na</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI_na</th>\n",
       "      <th>NONLIVINGAREA_MEDI_na</th>\n",
       "      <th>TOTALAREA_MODE_na</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123473</th>\n",
       "      <td>243191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>555273.0</td>\n",
       "      <td>16366.5</td>\n",
       "      <td>463500.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-23349</td>\n",
       "      <td>365243</td>\n",
       "      <td>-3595.0</td>\n",
       "      <td>-4408</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0.524685</td>\n",
       "      <td>0.358568</td>\n",
       "      <td>0.563835</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2058.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10118</th>\n",
       "      <td>111778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>198085.5</td>\n",
       "      <td>23638.5</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-10921</td>\n",
       "      <td>-117</td>\n",
       "      <td>-4281.0</td>\n",
       "      <td>-3399</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.244926</td>\n",
       "      <td>0.490305</td>\n",
       "      <td>0.595456</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.6464</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.6602</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0791</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0641</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>175057</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>776304.0</td>\n",
       "      <td>25173.0</td>\n",
       "      <td>648000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035792</td>\n",
       "      <td>-23213</td>\n",
       "      <td>-2157</td>\n",
       "      <td>-5680.0</td>\n",
       "      <td>-5009</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>0.643404</td>\n",
       "      <td>0.706205</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.7552</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.0746</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7648</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.0488</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1959.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  NAME_TYPE_SUITE  NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL  OCCUPATION_TYPE  CNT_FAM_MEMBERS  REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY  ORGANIZATION_TYPE  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG  LANDAREA_AVG  LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI  FONDKAPREMONT_MODE  HOUSETYPE_MODE  TOTALAREA_MODE  WALLSMATERIAL_MODE  EMERGENCYSTATE_MODE  OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  AMT_ANNUITY_na  AMT_GOODS_PRICE_na  OWN_CAR_AGE_na  CNT_FAM_MEMBERS_na  EXT_SOURCE_1_na  EXT_SOURCE_2_na  EXT_SOURCE_3_na  APARTMENTS_AVG_na  BASEMENTAREA_AVG_na  YEARS_BEGINEXPLUATATION_AVG_na  YEARS_BUILD_AVG_na  COMMONAREA_AVG_na  ELEVATORS_AVG_na  ENTRANCES_AVG_na  FLOORSMAX_AVG_na  FLOORSMIN_AVG_na  LANDAREA_AVG_na  LIVINGAPARTMENTS_AVG_na  LIVINGAREA_AVG_na  NONLIVINGAPARTMENTS_AVG_na  NONLIVINGAREA_AVG_na  APARTMENTS_MODE_na  BASEMENTAREA_MODE_na  YEARS_BEGINEXPLUATATION_MODE_na  YEARS_BUILD_MODE_na  COMMONAREA_MODE_na  ELEVATORS_MODE_na  ENTRANCES_MODE_na  FLOORSMAX_MODE_na  FLOORSMIN_MODE_na  LANDAREA_MODE_na  LIVINGAPARTMENTS_MODE_na  LIVINGAREA_MODE_na  NONLIVINGAPARTMENTS_MODE_na  NONLIVINGAREA_MODE_na  APARTMENTS_MEDI_na  BASEMENTAREA_MEDI_na  YEARS_BEGINEXPLUATATION_MEDI_na  YEARS_BUILD_MEDI_na  COMMONAREA_MEDI_na  ELEVATORS_MEDI_na  ENTRANCES_MEDI_na  FLOORSMAX_MEDI_na  FLOORSMIN_MEDI_na  LANDAREA_MEDI_na  LIVINGAPARTMENTS_MEDI_na  LIVINGAREA_MEDI_na  NONLIVINGAPARTMENTS_MEDI_na  NONLIVINGAREA_MEDI_na  TOTALAREA_MODE_na  OBS_30_CNT_SOCIAL_CIRCLE_na  DEF_30_CNT_SOCIAL_CIRCLE_na  OBS_60_CNT_SOCIAL_CIRCLE_na  DEF_60_CNT_SOCIAL_CIRCLE_na  DAYS_LAST_PHONE_CHANGE_na  AMT_REQ_CREDIT_BUREAU_HOUR_na  AMT_REQ_CREDIT_BUREAU_DAY_na  AMT_REQ_CREDIT_BUREAU_WEEK_na  AMT_REQ_CREDIT_BUREAU_MON_na  AMT_REQ_CREDIT_BUREAU_QRT_na  AMT_REQ_CREDIT_BUREAU_YEAR_na\n",
       "123473      243191       0                   1            1             2                1             0          171000.0    555273.0      16366.5         463500.0                7                 4                    5                   6                  2                    0.035792      -23349         365243            -3595.0            -4408         31.0           1               0                0                 1           0           0                0              1.0                     2                            2                           6                        9                           0                           0                            0                       0                       0                        0                 58      0.524685      0.358568      0.563835          0.0876            0.0763                       0.9821           0.7552          0.0211            0.0         0.1379         0.1667         0.2083        0.0483                0.0756          0.0745                   0.0000             0.0035           0.0840             0.0746                        0.9816            0.7648           0.0190             0.0          0.1379          0.1667          0.2083         0.0460                 0.0771           0.0731                    0.0000              0.0011           0.0864             0.0758                        0.9816            0.7585           0.0208             0.0          0.1379          0.1667          0.2083         0.0488                 0.0761           0.0749                    0.0000              0.0030                   0               0          0.0687                   0                    0                       0.0                       0.0                       0.0                       0.0                 -2058.0                0                1                0                0                0                0                0                0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                         0.0                        0.0                         0.0                        0.0                        1.0                         1.0               1                   1               1                   1                1                1                1                  2                    2                               2                   2                  2                 2                 2                 2                 2                2                        2                  2                           2                     2                   2                     2                                2                    2                   2                  2                  2                  2                  2                 2                         2                   2                            2                      2                   2                     2                                2                    2                   2                  2                  2                  2                  2                 2                         2                   2                            2                      2                  2                            1                            1                            1                            1                          1                              1                             1                              1                             1                             1                              1\n",
       "10118       111778       0                   1            2             1                2             1          157500.0    198085.5      23638.5         171000.0                7                 8                    5                   2                  2                    0.010032      -10921           -117            -4281.0            -3399          9.0           1               1                1                 1           1           0                9              3.0                     2                            2                           3                        7                           0                           0                            0                       0                       0                        0                  5      0.244926      0.490305      0.595456          0.0784            0.0633                       0.9742           0.6464          0.0266            0.0         0.1379         0.1667         0.2083        0.0409                0.0630          0.0594                   0.0039             0.0149           0.0798             0.0657                        0.9742            0.6602           0.0269             0.0          0.1379          0.1667          0.2083         0.0418                 0.0689           0.0619                    0.0039              0.0158           0.0791             0.0633                        0.9742            0.6511           0.0268             0.0          0.1379          0.1667          0.2083         0.0416                 0.0641           0.0605                    0.0039              0.0153                   3               1          0.0645                   6                    1                       1.0                       0.0                       1.0                       0.0                   -73.0                0                1                0                0                0                0                0                0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                         0.0                        0.0                         0.0                        0.0                        0.0                         1.0               1                   1               2                   1                1                1                1                  1                    1                               1                   1                  1                 1                 1                 1                 1                1                        1                  1                           1                     1                   1                     1                                1                    1                   1                  1                  1                  1                  1                 1                         1                   1                            1                      1                   1                     1                                1                    1                   1                  1                  1                  1                  1                 1                         1                   1                            1                      1                  1                            1                            1                            1                            1                          1                              1                             1                              1                             1                             1                              1\n",
       "64716       175057       1                   1            2             2                2             0          135000.0    776304.0      25173.0         648000.0                7                 8                    4                   1                  2                    0.035792      -23213          -2157            -5680.0            -5009          8.0           1               1                0                 1           0           0                5              2.0                     2                            2                           1                       13                           0                           0                            0                       0                       0                        0                 43      0.506427      0.643404      0.706205          0.0876            0.0763                       0.9821           0.7552          0.0211            0.0         0.1379         0.1667         0.2083        0.0483                0.0756          0.0745                   0.0000             0.0035           0.0840             0.0746                        0.9816            0.7648           0.0190             0.0          0.1379          0.1667          0.2083         0.0460                 0.0771           0.0731                    0.0000              0.0011           0.0864             0.0758                        0.9816            0.7585           0.0208             0.0          0.1379          0.1667          0.2083         0.0488                 0.0761           0.0749                    0.0000              0.0030                   0               0          0.0687                   0                    0                       2.0                       0.0                       2.0                       0.0                 -1959.0                0                0                0                0                0                0                1                0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                 0                         0.0                        0.0                         0.0                        0.0                        0.0                         5.0               1                   1               1                   1                2                1                1                  2                    2                               2                   2                  2                 2                 2                 2                 2                2                        2                  2                           2                     2                   2                     2                                2                    2                   2                  2                  2                  2                  2                 2                         2                   2                            2                      2                   2                     2                                2                    2                   2                  2                  2                  2                  2                 2                         2                   2                            2                      2                  2                            1                            1                            1                            1                          1                              1                             1                              1                             1                             1                              1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una vez hecho el preprocesamiento, se puede ver que los valores del dataframe son todos numéricos.\n",
    "to.items.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da982e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>FLOORSMAX_AVG</th>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <th>LIVINGAREA_AVG</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <th>NONLIVINGAREA_AVG</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <th>ELEVATORS_MODE</th>\n",
       "      <th>ENTRANCES_MODE</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <th>LIVINGAREA_MODE</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>AMT_ANNUITY_na</th>\n",
       "      <th>AMT_GOODS_PRICE_na</th>\n",
       "      <th>OWN_CAR_AGE_na</th>\n",
       "      <th>CNT_FAM_MEMBERS_na</th>\n",
       "      <th>EXT_SOURCE_1_na</th>\n",
       "      <th>EXT_SOURCE_2_na</th>\n",
       "      <th>EXT_SOURCE_3_na</th>\n",
       "      <th>APARTMENTS_AVG_na</th>\n",
       "      <th>BASEMENTAREA_AVG_na</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG_na</th>\n",
       "      <th>YEARS_BUILD_AVG_na</th>\n",
       "      <th>COMMONAREA_AVG_na</th>\n",
       "      <th>ELEVATORS_AVG_na</th>\n",
       "      <th>ENTRANCES_AVG_na</th>\n",
       "      <th>FLOORSMAX_AVG_na</th>\n",
       "      <th>FLOORSMIN_AVG_na</th>\n",
       "      <th>LANDAREA_AVG_na</th>\n",
       "      <th>LIVINGAPARTMENTS_AVG_na</th>\n",
       "      <th>LIVINGAREA_AVG_na</th>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG_na</th>\n",
       "      <th>NONLIVINGAREA_AVG_na</th>\n",
       "      <th>APARTMENTS_MODE_na</th>\n",
       "      <th>BASEMENTAREA_MODE_na</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE_na</th>\n",
       "      <th>YEARS_BUILD_MODE_na</th>\n",
       "      <th>COMMONAREA_MODE_na</th>\n",
       "      <th>ELEVATORS_MODE_na</th>\n",
       "      <th>ENTRANCES_MODE_na</th>\n",
       "      <th>FLOORSMAX_MODE_na</th>\n",
       "      <th>FLOORSMIN_MODE_na</th>\n",
       "      <th>LANDAREA_MODE_na</th>\n",
       "      <th>LIVINGAPARTMENTS_MODE_na</th>\n",
       "      <th>LIVINGAREA_MODE_na</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE_na</th>\n",
       "      <th>NONLIVINGAREA_MODE_na</th>\n",
       "      <th>APARTMENTS_MEDI_na</th>\n",
       "      <th>BASEMENTAREA_MEDI_na</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI_na</th>\n",
       "      <th>YEARS_BUILD_MEDI_na</th>\n",
       "      <th>COMMONAREA_MEDI_na</th>\n",
       "      <th>ELEVATORS_MEDI_na</th>\n",
       "      <th>ENTRANCES_MEDI_na</th>\n",
       "      <th>FLOORSMAX_MEDI_na</th>\n",
       "      <th>FLOORSMIN_MEDI_na</th>\n",
       "      <th>LANDAREA_MEDI_na</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI_na</th>\n",
       "      <th>LIVINGAREA_MEDI_na</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI_na</th>\n",
       "      <th>NONLIVINGAREA_MEDI_na</th>\n",
       "      <th>TOTALAREA_MODE_na</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE_na</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT_na</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>3.075110e+05</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.00000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.00000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>278180.518577</td>\n",
       "      <td>0.080729</td>\n",
       "      <td>1.095213</td>\n",
       "      <td>1.341669</td>\n",
       "      <td>1.340108</td>\n",
       "      <td>1.693673</td>\n",
       "      <td>0.417052</td>\n",
       "      <td>1.687979e+05</td>\n",
       "      <td>5.990260e+05</td>\n",
       "      <td>27108.490234</td>\n",
       "      <td>5.383162e+05</td>\n",
       "      <td>6.193580</td>\n",
       "      <td>5.670288</td>\n",
       "      <td>4.188273</td>\n",
       "      <td>2.472312</td>\n",
       "      <td>2.290390</td>\n",
       "      <td>0.020868</td>\n",
       "      <td>-16036.995067</td>\n",
       "      <td>63815.045904</td>\n",
       "      <td>-4986.120605</td>\n",
       "      <td>-2994.202373</td>\n",
       "      <td>10.041052</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.819889</td>\n",
       "      <td>0.199368</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.281066</td>\n",
       "      <td>0.056720</td>\n",
       "      <td>6.076361</td>\n",
       "      <td>2.152664</td>\n",
       "      <td>2.052463</td>\n",
       "      <td>2.031521</td>\n",
       "      <td>4.090732</td>\n",
       "      <td>12.063419</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>0.050769</td>\n",
       "      <td>0.040659</td>\n",
       "      <td>0.078173</td>\n",
       "      <td>0.230454</td>\n",
       "      <td>0.179555</td>\n",
       "      <td>30.450429</td>\n",
       "      <td>0.504552</td>\n",
       "      <td>5.145032e-01</td>\n",
       "      <td>0.516051</td>\n",
       "      <td>0.102297</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>0.979864</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.143771</td>\n",
       "      <td>0.196633</td>\n",
       "      <td>0.215886</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.083567</td>\n",
       "      <td>0.090886</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.014641</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.079969</td>\n",
       "      <td>0.979277</td>\n",
       "      <td>0.76307</td>\n",
       "      <td>0.026096</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>0.141521</td>\n",
       "      <td>0.194641</td>\n",
       "      <td>0.214653</td>\n",
       "      <td>0.053701</td>\n",
       "      <td>0.086133</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.012719</td>\n",
       "      <td>0.101889</td>\n",
       "      <td>0.080842</td>\n",
       "      <td>0.979629</td>\n",
       "      <td>0.757577</td>\n",
       "      <td>0.027969</td>\n",
       "      <td>0.036465</td>\n",
       "      <td>0.143517</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>0.215799</td>\n",
       "      <td>0.056262</td>\n",
       "      <td>0.084282</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.932438</td>\n",
       "      <td>0.510996</td>\n",
       "      <td>0.086209</td>\n",
       "      <td>2.543994</td>\n",
       "      <td>0.533587</td>\n",
       "      <td>1.417523</td>\n",
       "      <td>0.142944</td>\n",
       "      <td>1.400626</td>\n",
       "      <td>0.099717</td>\n",
       "      <td>-962.858154</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.710023</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.088055</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.081376</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.029723</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.229631</td>\n",
       "      <td>1.778463</td>\n",
       "      <td>1.000039</td>\n",
       "      <td>1.000904</td>\n",
       "      <td>1.659908</td>\n",
       "      <td>1.000007</td>\n",
       "      <td>1.563811</td>\n",
       "      <td>1.002146</td>\n",
       "      <td>1.198253</td>\n",
       "      <td>1.507497</td>\n",
       "      <td>1.585160</td>\n",
       "      <td>1.487810</td>\n",
       "      <td>1.664978</td>\n",
       "      <td>1.698723</td>\n",
       "      <td>1.532960</td>\n",
       "      <td>1.503488</td>\n",
       "      <td>1.497608</td>\n",
       "      <td>1.678486</td>\n",
       "      <td>1.593767</td>\n",
       "      <td>1.683550</td>\n",
       "      <td>1.501933</td>\n",
       "      <td>1.694330</td>\n",
       "      <td>1.551792</td>\n",
       "      <td>1.507497</td>\n",
       "      <td>1.585160</td>\n",
       "      <td>1.487810</td>\n",
       "      <td>1.664978</td>\n",
       "      <td>1.698723</td>\n",
       "      <td>1.532960</td>\n",
       "      <td>1.503488</td>\n",
       "      <td>1.497608</td>\n",
       "      <td>1.678486</td>\n",
       "      <td>1.593767</td>\n",
       "      <td>1.683550</td>\n",
       "      <td>1.501933</td>\n",
       "      <td>1.694330</td>\n",
       "      <td>1.551792</td>\n",
       "      <td>1.507497</td>\n",
       "      <td>1.585160</td>\n",
       "      <td>1.487810</td>\n",
       "      <td>1.664978</td>\n",
       "      <td>1.698723</td>\n",
       "      <td>1.532960</td>\n",
       "      <td>1.503488</td>\n",
       "      <td>1.497608</td>\n",
       "      <td>1.678486</td>\n",
       "      <td>1.593767</td>\n",
       "      <td>1.683550</td>\n",
       "      <td>1.501933</td>\n",
       "      <td>1.694330</td>\n",
       "      <td>1.551792</td>\n",
       "      <td>1.482685</td>\n",
       "      <td>1.003320</td>\n",
       "      <td>1.003320</td>\n",
       "      <td>1.003320</td>\n",
       "      <td>1.003320</td>\n",
       "      <td>1.000003</td>\n",
       "      <td>1.135016</td>\n",
       "      <td>1.135016</td>\n",
       "      <td>1.135016</td>\n",
       "      <td>1.135016</td>\n",
       "      <td>1.135016</td>\n",
       "      <td>1.135016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>102790.175348</td>\n",
       "      <td>0.272419</td>\n",
       "      <td>0.293509</td>\n",
       "      <td>0.474297</td>\n",
       "      <td>0.473746</td>\n",
       "      <td>0.460968</td>\n",
       "      <td>0.722121</td>\n",
       "      <td>2.371231e+05</td>\n",
       "      <td>4.024908e+05</td>\n",
       "      <td>14493.460938</td>\n",
       "      <td>3.692890e+05</td>\n",
       "      <td>1.817005</td>\n",
       "      <td>2.544525</td>\n",
       "      <td>1.298753</td>\n",
       "      <td>1.168884</td>\n",
       "      <td>0.951168</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>4363.988632</td>\n",
       "      <td>141275.766519</td>\n",
       "      <td>3522.886230</td>\n",
       "      <td>1509.450419</td>\n",
       "      <td>7.115229</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.384280</td>\n",
       "      <td>0.399526</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>0.449521</td>\n",
       "      <td>0.231307</td>\n",
       "      <td>5.491022</td>\n",
       "      <td>0.910679</td>\n",
       "      <td>0.509034</td>\n",
       "      <td>0.502737</td>\n",
       "      <td>2.149512</td>\n",
       "      <td>3.265832</td>\n",
       "      <td>0.122126</td>\n",
       "      <td>0.219526</td>\n",
       "      <td>0.197499</td>\n",
       "      <td>0.268444</td>\n",
       "      <td>0.421124</td>\n",
       "      <td>0.383817</td>\n",
       "      <td>20.463558</td>\n",
       "      <td>0.139411</td>\n",
       "      <td>1.908699e-01</td>\n",
       "      <td>0.174777</td>\n",
       "      <td>0.077412</td>\n",
       "      <td>0.053433</td>\n",
       "      <td>0.042441</td>\n",
       "      <td>0.065580</td>\n",
       "      <td>0.043108</td>\n",
       "      <td>0.100048</td>\n",
       "      <td>0.070746</td>\n",
       "      <td>0.106761</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>0.052496</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.079745</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.048158</td>\n",
       "      <td>0.077241</td>\n",
       "      <td>0.054674</td>\n",
       "      <td>0.046270</td>\n",
       "      <td>0.06378</td>\n",
       "      <td>0.042266</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>0.071245</td>\n",
       "      <td>0.105588</td>\n",
       "      <td>0.091846</td>\n",
       "      <td>0.052930</td>\n",
       "      <td>0.056639</td>\n",
       "      <td>0.080627</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>0.078146</td>\n",
       "      <td>0.053267</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>0.064878</td>\n",
       "      <td>0.043197</td>\n",
       "      <td>0.099811</td>\n",
       "      <td>0.070949</td>\n",
       "      <td>0.106998</td>\n",
       "      <td>0.092464</td>\n",
       "      <td>0.053142</td>\n",
       "      <td>0.054032</td>\n",
       "      <td>0.080999</td>\n",
       "      <td>0.026516</td>\n",
       "      <td>0.048623</td>\n",
       "      <td>1.418267</td>\n",
       "      <td>0.532238</td>\n",
       "      <td>0.079121</td>\n",
       "      <td>2.745148</td>\n",
       "      <td>0.513823</td>\n",
       "      <td>2.398396</td>\n",
       "      <td>0.446033</td>\n",
       "      <td>2.377224</td>\n",
       "      <td>0.361735</td>\n",
       "      <td>826.807251</td>\n",
       "      <td>0.006502</td>\n",
       "      <td>0.453752</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.122010</td>\n",
       "      <td>0.283376</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>0.273412</td>\n",
       "      <td>0.062295</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.062424</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.059268</td>\n",
       "      <td>0.054110</td>\n",
       "      <td>0.03476</td>\n",
       "      <td>0.099144</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>0.089798</td>\n",
       "      <td>0.024387</td>\n",
       "      <td>0.022518</td>\n",
       "      <td>0.018299</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.103037</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>0.856810</td>\n",
       "      <td>0.744059</td>\n",
       "      <td>1.765523</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.030054</td>\n",
       "      <td>0.473741</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.495912</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>0.398684</td>\n",
       "      <td>0.499945</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>0.499852</td>\n",
       "      <td>0.471999</td>\n",
       "      <td>0.458814</td>\n",
       "      <td>0.498913</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.467058</td>\n",
       "      <td>0.491130</td>\n",
       "      <td>0.465092</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.499945</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>0.499852</td>\n",
       "      <td>0.471999</td>\n",
       "      <td>0.458814</td>\n",
       "      <td>0.498913</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.467058</td>\n",
       "      <td>0.491130</td>\n",
       "      <td>0.465092</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.499945</td>\n",
       "      <td>0.492695</td>\n",
       "      <td>0.499852</td>\n",
       "      <td>0.471999</td>\n",
       "      <td>0.458814</td>\n",
       "      <td>0.498913</td>\n",
       "      <td>0.499989</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.467058</td>\n",
       "      <td>0.491130</td>\n",
       "      <td>0.465092</td>\n",
       "      <td>0.499997</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>0.497311</td>\n",
       "      <td>0.499701</td>\n",
       "      <td>0.057526</td>\n",
       "      <td>0.057526</td>\n",
       "      <td>0.057526</td>\n",
       "      <td>0.057526</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.341742</td>\n",
       "      <td>0.341742</td>\n",
       "      <td>0.341742</td>\n",
       "      <td>0.341742</td>\n",
       "      <td>0.341742</td>\n",
       "      <td>0.341742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.565000e+04</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>1615.500000</td>\n",
       "      <td>4.050000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-25229.000000</td>\n",
       "      <td>-17912.000000</td>\n",
       "      <td>-24672.000000</td>\n",
       "      <td>-7197.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>8.173617e-08</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4292.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>189145.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125000e+05</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>16524.000000</td>\n",
       "      <td>2.385000e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>-19682.000000</td>\n",
       "      <td>-2760.000000</td>\n",
       "      <td>-7479.500000</td>\n",
       "      <td>-4299.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>3.929737e-01</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.981100</td>\n",
       "      <td>0.76480</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.758500</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1570.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>278202.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.471500e+05</td>\n",
       "      <td>5.135310e+05</td>\n",
       "      <td>24903.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>-15750.000000</td>\n",
       "      <td>-1213.000000</td>\n",
       "      <td>-4504.000000</td>\n",
       "      <td>-3254.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>5.658916e-01</td>\n",
       "      <td>0.537070</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.76480</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.758500</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-757.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>367142.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.025000e+05</td>\n",
       "      <td>8.086500e+05</td>\n",
       "      <td>34596.000000</td>\n",
       "      <td>6.795000e+05</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-12413.000000</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-2010.000000</td>\n",
       "      <td>-1720.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.506427</td>\n",
       "      <td>6.634218e-01</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.76480</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.075800</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>0.758500</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.166700</td>\n",
       "      <td>0.208300</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-274.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>456255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.170000e+08</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>258025.500000</td>\n",
       "      <td>4.050000e+06</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.072508</td>\n",
       "      <td>-7489.000000</td>\n",
       "      <td>365243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.962693</td>\n",
       "      <td>8.549997e-01</td>\n",
       "      <td>0.896010</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SK_ID_CURR         TARGET  NAME_CONTRACT_TYPE    CODE_GENDER   FLAG_OWN_CAR  FLAG_OWN_REALTY   CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT    AMT_ANNUITY  AMT_GOODS_PRICE  NAME_TYPE_SUITE  NAME_INCOME_TYPE  NAME_EDUCATION_TYPE  NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  REGION_POPULATION_RELATIVE     DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  DAYS_ID_PUBLISH    OWN_CAR_AGE     FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  FLAG_CONT_MOBILE     FLAG_PHONE     FLAG_EMAIL  OCCUPATION_TYPE  CNT_FAM_MEMBERS  REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY  ORGANIZATION_TYPE   EXT_SOURCE_1  EXT_SOURCE_2   EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  ELEVATORS_AVG  ENTRANCES_AVG  FLOORSMAX_AVG  FLOORSMIN_AVG   LANDAREA_AVG  LIVINGAPARTMENTS_AVG  LIVINGAREA_AVG  NONLIVINGAPARTMENTS_AVG  NONLIVINGAREA_AVG  APARTMENTS_MODE  BASEMENTAREA_MODE  YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_MODE  COMMONAREA_MODE  ELEVATORS_MODE  ENTRANCES_MODE  FLOORSMAX_MODE  FLOORSMIN_MODE  LANDAREA_MODE  LIVINGAPARTMENTS_MODE  LIVINGAREA_MODE  NONLIVINGAPARTMENTS_MODE  NONLIVINGAREA_MODE  APARTMENTS_MEDI  BASEMENTAREA_MEDI  YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  COMMONAREA_MEDI  ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  FLOORSMIN_MEDI  LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI  FONDKAPREMONT_MODE  HOUSETYPE_MODE  TOTALAREA_MODE  WALLSMATERIAL_MODE  EMERGENCYSTATE_MODE  OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  AMT_ANNUITY_na  AMT_GOODS_PRICE_na  OWN_CAR_AGE_na  CNT_FAM_MEMBERS_na  EXT_SOURCE_1_na  EXT_SOURCE_2_na  EXT_SOURCE_3_na  APARTMENTS_AVG_na  BASEMENTAREA_AVG_na  YEARS_BEGINEXPLUATATION_AVG_na  YEARS_BUILD_AVG_na  COMMONAREA_AVG_na  ELEVATORS_AVG_na  ENTRANCES_AVG_na  FLOORSMAX_AVG_na  FLOORSMIN_AVG_na  LANDAREA_AVG_na  LIVINGAPARTMENTS_AVG_na  LIVINGAREA_AVG_na  NONLIVINGAPARTMENTS_AVG_na  NONLIVINGAREA_AVG_na  APARTMENTS_MODE_na  BASEMENTAREA_MODE_na  YEARS_BEGINEXPLUATATION_MODE_na  YEARS_BUILD_MODE_na  COMMONAREA_MODE_na  ELEVATORS_MODE_na  ENTRANCES_MODE_na  FLOORSMAX_MODE_na  FLOORSMIN_MODE_na  LANDAREA_MODE_na  LIVINGAPARTMENTS_MODE_na  LIVINGAREA_MODE_na  NONLIVINGAPARTMENTS_MODE_na  NONLIVINGAREA_MODE_na  APARTMENTS_MEDI_na  BASEMENTAREA_MEDI_na  YEARS_BEGINEXPLUATATION_MEDI_na  YEARS_BUILD_MEDI_na  COMMONAREA_MEDI_na  ELEVATORS_MEDI_na  ENTRANCES_MEDI_na  FLOORSMAX_MEDI_na  FLOORSMIN_MEDI_na  LANDAREA_MEDI_na  LIVINGAPARTMENTS_MEDI_na  LIVINGAREA_MEDI_na  NONLIVINGAPARTMENTS_MEDI_na  NONLIVINGAREA_MEDI_na  TOTALAREA_MODE_na  OBS_30_CNT_SOCIAL_CIRCLE_na  DEF_30_CNT_SOCIAL_CIRCLE_na  OBS_60_CNT_SOCIAL_CIRCLE_na  DEF_60_CNT_SOCIAL_CIRCLE_na  DAYS_LAST_PHONE_CHANGE_na  AMT_REQ_CREDIT_BUREAU_HOUR_na  AMT_REQ_CREDIT_BUREAU_DAY_na  AMT_REQ_CREDIT_BUREAU_WEEK_na  AMT_REQ_CREDIT_BUREAU_MON_na  AMT_REQ_CREDIT_BUREAU_QRT_na  AMT_REQ_CREDIT_BUREAU_YEAR_na\n",
       "count  307511.000000  307511.000000       307511.000000  307511.000000  307511.000000    307511.000000  307511.000000      3.075110e+05  3.075110e+05  307511.000000     3.075110e+05    307511.000000     307511.000000        307511.000000       307511.000000      307511.000000               307511.000000  307511.000000  307511.000000      307511.000000    307511.000000  307511.000000  307511.000000   307511.000000    307511.000000     307511.000000  307511.000000  307511.000000    307511.000000    307511.000000         307511.000000                307511.000000               307511.000000            307511.000000               307511.000000               307511.000000                307511.000000           307511.000000           307511.000000            307511.000000      307511.000000  307511.000000  3.075110e+05  307511.000000   307511.000000     307511.000000                307511.000000    307511.000000   307511.000000  307511.000000  307511.000000  307511.000000  307511.000000  307511.000000         307511.000000   307511.000000            307511.000000      307511.000000    307511.000000      307511.000000                 307511.000000      307511.00000    307511.000000   307511.000000   307511.000000   307511.000000   307511.000000  307511.000000          307511.000000    307511.000000             307511.000000       307511.000000    307511.000000      307511.000000                 307511.000000     307511.000000    307511.000000   307511.000000   307511.000000   307511.000000   307511.000000  307511.000000          307511.000000    307511.000000             307511.000000       307511.000000       307511.000000   307511.000000   307511.000000       307511.000000        307511.000000             307511.000000             307511.000000             307511.000000             307511.000000           307511.000000    307511.000000    307511.000000    307511.000000    307511.000000    307511.000000    307511.000000    307511.000000    307511.000000     307511.000000     307511.000000     307511.000000     307511.000000     307511.000000      307511.00000     307511.000000     307511.000000     307511.000000     307511.000000     307511.000000     307511.000000               307511.000000              307511.000000               307511.000000              307511.000000              307511.000000               307511.000000   307511.000000       307511.000000   307511.000000       307511.000000    307511.000000    307511.000000    307511.000000      307511.000000        307511.000000                   307511.000000       307511.000000      307511.000000     307511.000000     307511.000000     307511.000000     307511.000000    307511.000000            307511.000000      307511.000000               307511.000000         307511.000000       307511.000000         307511.000000                    307511.000000        307511.000000       307511.000000      307511.000000      307511.000000      307511.000000      307511.000000     307511.000000             307511.000000       307511.000000                307511.000000          307511.000000       307511.000000         307511.000000                    307511.000000        307511.000000       307511.000000      307511.000000      307511.000000      307511.000000      307511.000000     307511.000000             307511.000000       307511.000000                307511.000000          307511.000000      307511.000000                307511.000000                307511.000000                307511.000000                307511.000000              307511.000000                  307511.000000                 307511.000000                  307511.000000                 307511.000000                 307511.000000                  307511.000000\n",
       "mean   278180.518577       0.080729            1.095213       1.341669       1.340108         1.693673       0.417052      1.687979e+05  5.990260e+05   27108.490234     5.383162e+05         6.193580          5.670288             4.188273            2.472312           2.290390                    0.020868  -16036.995067   63815.045904       -4986.120605     -2994.202373      10.041052       0.999997        0.819889         0.199368          0.998133       0.281066       0.056720         6.076361         2.152664              2.052463                     2.031521                    4.090732                12.063419                    0.015144                    0.050769                     0.040659                0.078173                0.230454                 0.179555          30.450429       0.504552  5.145032e-01       0.516051        0.102297          0.081337                     0.979864         0.754286        0.028186       0.036869       0.143771       0.196633       0.215886       0.055626              0.083567        0.090886                 0.002693           0.014641         0.098889           0.079969                      0.979277           0.76307         0.026096        0.034790        0.141521        0.194641        0.214653       0.053701               0.086133         0.089474                  0.002469            0.012719         0.101889           0.080842                      0.979629          0.757577         0.027969        0.036465        0.143517        0.196440        0.215799       0.056262               0.084282         0.091688                  0.002644            0.014311            0.932438        0.510996        0.086209            2.543994             0.533587                  1.417523                  0.142944                  1.400626                  0.099717             -962.858154         0.000042         0.710023         0.000081         0.015115         0.088055         0.000192         0.081376         0.003896          0.000023          0.003912          0.000007          0.003525          0.002936           0.00121          0.009928          0.000267          0.008130          0.000595          0.000507          0.000335                    0.005538                   0.006055                    0.029723                   0.231293                   0.229631                    1.778463        1.000039            1.000904        1.659908            1.000007         1.563811         1.002146         1.198253           1.507497             1.585160                        1.487810            1.664978           1.698723          1.532960          1.503488          1.497608          1.678486         1.593767                 1.683550           1.501933                    1.694330              1.551792            1.507497              1.585160                         1.487810             1.664978            1.698723           1.532960           1.503488           1.497608           1.678486          1.593767                  1.683550            1.501933                     1.694330               1.551792            1.507497              1.585160                         1.487810             1.664978            1.698723           1.532960           1.503488           1.497608           1.678486          1.593767                  1.683550            1.501933                     1.694330               1.551792           1.482685                     1.003320                     1.003320                     1.003320                     1.003320                   1.000003                       1.135016                      1.135016                       1.135016                      1.135016                      1.135016                       1.135016\n",
       "std    102790.175348       0.272419            0.293509       0.474297       0.473746         0.460968       0.722121      2.371231e+05  4.024908e+05   14493.460938     3.692890e+05         1.817005          2.544525             1.298753            1.168884           0.951168                    0.013831    4363.988632  141275.766519        3522.886230      1509.450419       7.115229       0.001803        0.384280         0.399526          0.043164       0.449521       0.231307         5.491022         0.910679              0.509034                     0.502737                    2.149512                 3.265832                    0.122126                    0.219526                     0.197499                0.268444                0.421124                 0.383817          20.463558       0.139411  1.908699e-01       0.174777        0.077412          0.053433                     0.042441         0.065580        0.043108       0.100048       0.070746       0.106761       0.092167       0.052496              0.053378        0.079745                 0.026700           0.048158         0.077241           0.054674                      0.046270           0.06378         0.042266        0.097726        0.071245        0.105588        0.091846       0.052930               0.056639         0.080627                  0.025854            0.048768         0.078146           0.053267                      0.042910          0.064878         0.043197        0.099811        0.070949        0.106998        0.092464       0.053142               0.054032         0.080999                  0.026516            0.048623            1.418267        0.532238        0.079121            2.745148             0.513823                  2.398396                  0.446033                  2.377224                  0.361735              826.807251         0.006502         0.453752         0.009016         0.122010         0.283376         0.013850         0.273412         0.062295          0.004771          0.062424          0.002550          0.059268          0.054110           0.03476          0.099144          0.016327          0.089798          0.024387          0.022518          0.018299                    0.078014                   0.103037                    0.190728                   0.856810                   0.744059                    1.765523        0.006247            0.030054        0.473741            0.002550         0.495912         0.046278         0.398684           0.499945             0.492695                        0.499852            0.471999           0.458814          0.498913          0.499989          0.499995          0.467058         0.491130                 0.465092           0.499997                    0.460692              0.497311            0.499945              0.492695                         0.499852             0.471999            0.458814           0.498913           0.499989           0.499995           0.467058          0.491130                  0.465092            0.499997                     0.460692               0.497311            0.499945              0.492695                         0.499852             0.471999            0.458814           0.498913           0.499989           0.499995           0.467058          0.491130                  0.465092            0.499997                     0.460692               0.497311           0.499701                     0.057526                     0.057526                     0.057526                     0.057526                   0.001803                       0.341742                      0.341742                       0.341742                      0.341742                      0.341742                       0.341742\n",
       "min    100002.000000       0.000000            1.000000       1.000000       1.000000         1.000000       0.000000      2.565000e+04  4.500000e+04    1615.500000     4.050000e+04         0.000000          1.000000             1.000000            1.000000           1.000000                    0.000290  -25229.000000  -17912.000000      -24672.000000     -7197.000000       0.000000       0.000000        0.000000         0.000000          0.000000       0.000000       0.000000         0.000000         1.000000              1.000000                     1.000000                    1.000000                 0.000000                    0.000000                    0.000000                     0.000000                0.000000                0.000000                 0.000000           1.000000       0.014568  8.173617e-08       0.000527        0.000000          0.000000                     0.000000         0.000000        0.000000       0.000000       0.000000       0.000000       0.000000       0.000000              0.000000        0.000000                 0.000000           0.000000         0.000000           0.000000                      0.000000           0.00000         0.000000        0.000000        0.000000        0.000000        0.000000       0.000000               0.000000         0.000000                  0.000000            0.000000         0.000000           0.000000                      0.000000          0.000000         0.000000        0.000000        0.000000        0.000000        0.000000       0.000000               0.000000         0.000000                  0.000000            0.000000            0.000000        0.000000        0.000000            0.000000             0.000000                  0.000000                  0.000000                  0.000000                  0.000000            -4292.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000          0.000000          0.000000          0.000000          0.000000          0.000000           0.00000          0.000000          0.000000          0.000000          0.000000          0.000000          0.000000                    0.000000                   0.000000                    0.000000                   0.000000                   0.000000                    0.000000        1.000000            1.000000        1.000000            1.000000         1.000000         1.000000         1.000000           1.000000             1.000000                        1.000000            1.000000           1.000000          1.000000          1.000000          1.000000          1.000000         1.000000                 1.000000           1.000000                    1.000000              1.000000            1.000000              1.000000                         1.000000             1.000000            1.000000           1.000000           1.000000           1.000000           1.000000          1.000000                  1.000000            1.000000                     1.000000               1.000000            1.000000              1.000000                         1.000000             1.000000            1.000000           1.000000           1.000000           1.000000           1.000000          1.000000                  1.000000            1.000000                     1.000000               1.000000           1.000000                     1.000000                     1.000000                     1.000000                     1.000000                   1.000000                       1.000000                      1.000000                       1.000000                      1.000000                      1.000000                       1.000000\n",
       "25%    189145.500000       0.000000            1.000000       1.000000       1.000000         1.000000       0.000000      1.125000e+05  2.700000e+05   16524.000000     2.385000e+05         7.000000          4.000000             3.000000            2.000000           2.000000                    0.010006  -19682.000000   -2760.000000       -7479.500000     -4299.000000       9.000000       1.000000        1.000000         0.000000          1.000000       0.000000       0.000000         0.000000         2.000000              2.000000                     2.000000                    2.000000                10.000000                    0.000000                    0.000000                     0.000000                0.000000                0.000000                 0.000000           6.000000       0.506427  3.929737e-01       0.417100        0.087600          0.076300                     0.981600         0.755200        0.021100       0.000000       0.137900       0.166700       0.208300       0.048300              0.075600        0.074500                 0.000000           0.003500         0.084000           0.074600                      0.981100           0.76480         0.019000        0.000000        0.137900        0.166700        0.208300       0.046000               0.077100         0.073100                  0.000000            0.001100         0.086400           0.075800                      0.981600          0.758500         0.020800        0.000000        0.137900        0.166700        0.208300       0.048800               0.076100         0.074900                  0.000000            0.003000            0.000000        0.000000        0.067000            0.000000             0.000000                  0.000000                  0.000000                  0.000000                  0.000000            -1570.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000          0.000000          0.000000          0.000000          0.000000          0.000000           0.00000          0.000000          0.000000          0.000000          0.000000          0.000000          0.000000                    0.000000                   0.000000                    0.000000                   0.000000                   0.000000                    1.000000        1.000000            1.000000        1.000000            1.000000         1.000000         1.000000         1.000000           1.000000             1.000000                        1.000000            1.000000           1.000000          1.000000          1.000000          1.000000          1.000000         1.000000                 1.000000           1.000000                    1.000000              1.000000            1.000000              1.000000                         1.000000             1.000000            1.000000           1.000000           1.000000           1.000000           1.000000          1.000000                  1.000000            1.000000                     1.000000               1.000000            1.000000              1.000000                         1.000000             1.000000            1.000000           1.000000           1.000000           1.000000           1.000000          1.000000                  1.000000            1.000000                     1.000000               1.000000           1.000000                     1.000000                     1.000000                     1.000000                     1.000000                   1.000000                       1.000000                      1.000000                       1.000000                      1.000000                      1.000000                       1.000000\n",
       "50%    278202.000000       0.000000            1.000000       1.000000       1.000000         2.000000       0.000000      1.471500e+05  5.135310e+05   24903.000000     4.500000e+05         7.000000          8.000000             5.000000            2.000000           2.000000                    0.018850  -15750.000000   -1213.000000       -4504.000000     -3254.000000       9.000000       1.000000        1.000000         0.000000          1.000000       0.000000       0.000000         5.000000         2.000000              2.000000                     2.000000                    5.000000                12.000000                    0.000000                    0.000000                     0.000000                0.000000                0.000000                 0.000000          34.000000       0.506427  5.658916e-01       0.537070        0.087600          0.076300                     0.982100         0.755200        0.021100       0.000000       0.137900       0.166700       0.208300       0.048300              0.075600        0.074500                 0.000000           0.003500         0.084000           0.074600                      0.981600           0.76480         0.019000        0.000000        0.137900        0.166700        0.208300       0.046000               0.077100         0.073100                  0.000000            0.001100         0.086400           0.075800                      0.981600          0.758500         0.020800        0.000000        0.137900        0.166700        0.208300       0.048800               0.076100         0.074900                  0.000000            0.003000            0.000000        0.000000        0.068700            0.000000             1.000000                  0.000000                  0.000000                  0.000000                  0.000000             -757.000000         0.000000         1.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000          0.000000          0.000000          0.000000          0.000000          0.000000           0.00000          0.000000          0.000000          0.000000          0.000000          0.000000          0.000000                    0.000000                   0.000000                    0.000000                   0.000000                   0.000000                    1.000000        1.000000            1.000000        2.000000            1.000000         2.000000         1.000000         1.000000           2.000000             2.000000                        1.000000            2.000000           2.000000          2.000000          2.000000          1.000000          2.000000         2.000000                 2.000000           2.000000                    2.000000              2.000000            2.000000              2.000000                         1.000000             2.000000            2.000000           2.000000           2.000000           1.000000           2.000000          2.000000                  2.000000            2.000000                     2.000000               2.000000            2.000000              2.000000                         1.000000             2.000000            2.000000           2.000000           2.000000           1.000000           2.000000          2.000000                  2.000000            2.000000                     2.000000               2.000000           1.000000                     1.000000                     1.000000                     1.000000                     1.000000                   1.000000                       1.000000                      1.000000                       1.000000                      1.000000                      1.000000                       1.000000\n",
       "75%    367142.500000       0.000000            1.000000       2.000000       2.000000         2.000000       1.000000      2.025000e+05  8.086500e+05   34596.000000     6.795000e+05         7.000000          8.000000             5.000000            3.000000           2.000000                    0.028663  -12413.000000    -289.000000       -2010.000000     -1720.000000       9.000000       1.000000        1.000000         0.000000          1.000000       1.000000       0.000000        10.000000         3.000000              2.000000                     2.000000                    6.000000                14.000000                    0.000000                    0.000000                     0.000000                0.000000                0.000000                 0.000000          48.000000       0.506427  6.634218e-01       0.636376        0.087600          0.076300                     0.982100         0.755200        0.021100       0.000000       0.137900       0.166700       0.208300       0.048300              0.075600        0.074500                 0.000000           0.003500         0.084000           0.074600                      0.981600           0.76480         0.019000        0.000000        0.137900        0.166700        0.208300       0.046000               0.077100         0.073100                  0.000000            0.001100         0.086400           0.075800                      0.982100          0.758500         0.020800        0.000000        0.137900        0.166700        0.208300       0.048800               0.076100         0.074900                  0.000000            0.003000            3.000000        1.000000        0.070300            5.000000             1.000000                  2.000000                  0.000000                  2.000000                  0.000000             -274.000000         0.000000         1.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000          0.000000          0.000000          0.000000          0.000000          0.000000           0.00000          0.000000          0.000000          0.000000          0.000000          0.000000          0.000000                    0.000000                   0.000000                    0.000000                   0.000000                   0.000000                    3.000000        1.000000            1.000000        2.000000            1.000000         2.000000         1.000000         1.000000           2.000000             2.000000                        2.000000            2.000000           2.000000          2.000000          2.000000          2.000000          2.000000         2.000000                 2.000000           2.000000                    2.000000              2.000000            2.000000              2.000000                         2.000000             2.000000            2.000000           2.000000           2.000000           2.000000           2.000000          2.000000                  2.000000            2.000000                     2.000000               2.000000            2.000000              2.000000                         2.000000             2.000000            2.000000           2.000000           2.000000           2.000000           2.000000          2.000000                  2.000000            2.000000                     2.000000               2.000000           2.000000                     1.000000                     1.000000                     1.000000                     1.000000                   1.000000                       1.000000                      1.000000                       1.000000                      1.000000                      1.000000                       1.000000\n",
       "max    456255.000000       1.000000            2.000000       3.000000       2.000000         2.000000      19.000000      1.170000e+08  4.050000e+06  258025.500000     4.050000e+06         7.000000          8.000000             5.000000            6.000000           6.000000                    0.072508   -7489.000000  365243.000000           0.000000         0.000000      91.000000       1.000000        1.000000         1.000000          1.000000       1.000000       1.000000        18.000000        20.000000              3.000000                     3.000000                    7.000000                23.000000                    1.000000                    1.000000                     1.000000                1.000000                1.000000                 1.000000          58.000000       0.962693  8.549997e-01       0.896010        1.000000          1.000000                     1.000000         1.000000        1.000000       1.000000       1.000000       1.000000       1.000000       1.000000              1.000000        1.000000                 1.000000           1.000000         1.000000           1.000000                      1.000000           1.00000         1.000000        1.000000        1.000000        1.000000        1.000000       1.000000               1.000000         1.000000                  1.000000            1.000000         1.000000           1.000000                      1.000000          1.000000         1.000000        1.000000        1.000000        1.000000        1.000000       1.000000               1.000000         1.000000                  1.000000            1.000000            4.000000        3.000000        1.000000            7.000000             2.000000                348.000000                 34.000000                344.000000                 24.000000                0.000000         1.000000         1.000000         1.000000         1.000000         1.000000         1.000000         1.000000         1.000000          1.000000          1.000000          1.000000          1.000000          1.000000           1.00000          1.000000          1.000000          1.000000          1.000000          1.000000          1.000000                    4.000000                   9.000000                    8.000000                  27.000000                 261.000000                   25.000000        2.000000            2.000000        2.000000            2.000000         2.000000         2.000000         2.000000           2.000000             2.000000                        2.000000            2.000000           2.000000          2.000000          2.000000          2.000000          2.000000         2.000000                 2.000000           2.000000                    2.000000              2.000000            2.000000              2.000000                         2.000000             2.000000            2.000000           2.000000           2.000000           2.000000           2.000000          2.000000                  2.000000            2.000000                     2.000000               2.000000            2.000000              2.000000                         2.000000             2.000000            2.000000           2.000000           2.000000           2.000000           2.000000          2.000000                  2.000000            2.000000                     2.000000               2.000000           2.000000                     2.000000                     2.000000                     2.000000                     2.000000                   2.000000                       2.000000                      2.000000                       2.000000                      2.000000                      2.000000                       2.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.items.describe(include='all')  # Para ver estadísticas generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69030966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 246008 entries, 123473 to 121958\n",
      "Columns: 182 entries, NAME_CONTRACT_TYPE to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float32(65), int16(2), int32(2), int8(113)\n",
      "memory usage: 92.2 MB\n"
     ]
    }
   ],
   "source": [
    "to.train.xs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f9ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que el preprocesamiento puede tardar, guardamos el objeto en memoria para futuro uso\n",
    "save_pickle('./application_train-tabular-object.pkl',to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23830c24",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3190449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression RMSE: 0.2748\n",
      "KNeighborsRegressor RMSE: 0.3018\n",
      "AdaBoostRegressor RMSE: 0.2905\n",
      "DecisionTreeRegressor RMSE: 0.3221\n",
      "GradientBoostingRegressor RMSE: 0.2741\n",
      "BaggingRegressor RMSE: 0.2837\n",
      "RandomForestRegressor RMSE: 0.2751\n",
      "LGBMRegressor RMSE: 0.2828\n",
      "XGBRegressor RMSE: 0.2826\n",
      "CatBoostRegressor RMSE: 0.2744\n"
     ]
    }
   ],
   "source": [
    "# Cargar el objeto TabularPandas desde el pickle\n",
    "to = load_pickle('./application_train-tabular-object.pkl')\n",
    "\n",
    "# Extraer features y target\n",
    "xs, y = to.train.xs, to.train.y\n",
    "valid_xs, valid_y = to.valid.xs, to.valid.y\n",
    "\n",
    "# Muestreo\n",
    "sample_frac = 0.05   # 5% de las filas\n",
    "sampled_xs = xs.sample(frac=sample_frac, random_state=42)\n",
    "sampled_y = y.loc[sampled_xs.index] \n",
    "\n",
    "# Copias para trabajar con scikit-learn\n",
    "X = sampled_xs.copy()\n",
    "target = sampled_y.copy()\n",
    "\n",
    "# Ejecutar evaluación\n",
    "fit_transform_model(X, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f5a247",
   "metadata": {},
   "source": [
    "## Model test with all data joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273279c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression RMSE: 0.2751\n",
      "KNeighborsRegressor RMSE: 0.3032\n",
      "AdaBoostRegressor RMSE: 0.2850\n",
      "DecisionTreeRegressor RMSE: 0.3045\n",
      "GradientBoostingRegressor RMSE: 0.2722\n",
      "BaggingRegressor RMSE: 0.2773\n",
      "RandomForestRegressor RMSE: 0.2715\n",
      "LGBMRegressor RMSE: 0.2763\n",
      "XGBRegressor RMSE: 0.2791\n",
      "CatBoostRegressor RMSE: 0.2726\n"
     ]
    }
   ],
   "source": [
    "# Cargar el objeto TabularPandas desde el pickle\n",
    "to = load_pickle('./prework-tabular-object.pkl')\n",
    "\n",
    "# Extraer features y target\n",
    "xs, y = to.train.xs, to.train.y\n",
    "valid_xs, valid_y = to.valid.xs, to.valid.y\n",
    "\n",
    "# Muestreo\n",
    "sample_frac = 0.05   # 5% de las filas\n",
    "sampled_xs = xs.sample(frac=sample_frac, random_state=42)\n",
    "sampled_y = y.loc[sampled_xs.index] \n",
    "\n",
    "# Copias para trabajar con scikit-learn\n",
    "# X = sampled_xs.copy()\n",
    "X = clean_column_names(sampled_xs)\n",
    "target = sampled_y.copy()\n",
    "\n",
    "# Ejecutar evaluación\n",
    "fit_transform_model(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4c575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
